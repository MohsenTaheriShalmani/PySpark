{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Alternative approach\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4OJOaxO_6r-",
        "outputId": "bae3d66b-91b5-4fab-f06a-13c56d751032"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488493 sha256=2599fc645ef1a5de92494ed8b159a649d621ebeea47113ff2674eaf8cfadfe7e\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mP9Oh1Jtoujz",
        "outputId": "68085891-e366-469e-cc8d-367316d76724"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import pyspark\n",
        "import json\n",
        "import pandas as pd\n",
        "import gzip\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "import re"
      ],
      "metadata": {
        "id": "WGs2gE8yAK1n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extract data by start and end\n",
        "def extraxtString(string,startString,endString):\n",
        "    startingPoint=0\n",
        "    lengthString=len(string)\n",
        "    myList = []\n",
        "    continueYes = 1\n",
        "    while(continueYes == 1 and startingPoint < lengthString):\n",
        "        temp1=string.find(startString,startingPoint)\n",
        "        if(temp1 != -1):\n",
        "            temp1 = temp1+len(startString)\n",
        "            temp2 = string.find(endString,temp1)\n",
        "            if(temp2 != -1):\n",
        "                #middleString=string[temp1:temp2]\n",
        "                middleString=string[(temp1-len(startString)):temp2]\n",
        "                myList.append(middleString)\n",
        "                #startingPoint=temp2+len(endString)\n",
        "                startingPoint=temp2\n",
        "            else:\n",
        "                continueYes=0\n",
        "        else:\n",
        "            continueYes=0\n",
        "    return myList"
      ],
      "metadata": {
        "id": "ur2DqTXj_l7A"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql.functions import from_json, udf, col, lower, regexp_replace, split, when\n",
        "from pyspark.sql.functions import rand #additional library for optimization\n",
        "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType, BooleanType\n",
        "import random\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "import time\n"
      ],
      "metadata": {
        "id": "ql96Sct8GMyh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install delta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za-SLtTto3mJ",
        "outputId": "bd98e9cb-33d0-4709-e0de-5c97bf18f550"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting delta\n",
            "  Downloading delta-0.4.2.tar.gz (4.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: delta\n",
            "  Building wheel for delta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for delta: filename=delta-0.4.2-py3-none-any.whl size=2914 sha256=2dd682ddc2b31017b28cb7faa9286f032e94709ab696e01283c625757942ba29\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/86/24/a486f14769cf86a2a9ce6b589a82b7414b14657c6fd515dc75\n",
            "Successfully built delta\n",
            "Installing collected packages: delta\n",
            "Successfully installed delta-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib-venn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "li0YyDNIppq3",
        "outputId": "5c60fefa-ab9e-44a8-88ee-b86fcd0ee3ac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib-venn in /usr/local/lib/python3.10/dist-packages (0.11.10)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from matplotlib-venn) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from matplotlib-venn) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from matplotlib-venn) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->matplotlib-venn) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install delta-spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Elv26CbOgi5l",
        "outputId": "c1c4dd52-2c57-40bd-e802-e88c4f793430"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: delta-spark in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: pyspark<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from delta-spark) (3.5.1)\n",
            "Requirement already satisfied: importlib-metadata>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from delta-spark) (7.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.0.0->delta-spark) (3.17.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark<3.6.0,>=3.5.0->delta-spark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql.functions import from_json, udf, col, lower, regexp_replace, split, when\n",
        "from pyspark.sql.functions import rand #additional library for optimization\n",
        "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType, BooleanType\n",
        "import random\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "import time\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from delta import configure_spark_with_delta_pip"
      ],
      "metadata": {
        "id": "kZlXVBiGq9b0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.base import Transformer\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession, DataFrame\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.sql.types import IntegerType, StringType, ArrayType\n",
        "from pyspark.sql.functions import when"
      ],
      "metadata": {
        "id": "W7ijCOarzhJg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Added last two .config to allocate memory and ensure 4 cores to be utilized\n",
        "#Set memory per exector to 2g to be able to handle the 5GB file\n",
        "builder = SparkSession.builder.appName(\"amazon\") \\\n",
        "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
        "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
        "    .config(\"spark.executor.cores\", \"3\") \\\n",
        "    .config(\"spark.executor.instances\", \"4\") \\\n",
        "    .config(\"spark.executor.memory\", \"2g\")\n",
        "\n",
        "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
      ],
      "metadata": {
        "id": "kgWMftDCpvoI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a dataframe from the txt file by reading it as json for formating\n",
        "df = spark.read.json(\"/content/drive/MyDrive/GoogleColab/Video_Games_5.json.gz\")"
      ],
      "metadata": {
        "id": "kPMX2u5jp3Cm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBbIC7AOqFuw",
        "outputId": "2a235d43-2e7c-4c4d-ea49-a60f2801dd1a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-------+--------------------+-----------+--------------+-----------------+-----+--------------------+--------------+--------+----+\n",
            "|      asin|image|overall|          reviewText| reviewTime|    reviewerID|     reviewerName|style|             summary|unixReviewTime|verified|vote|\n",
            "+----------+-----+-------+--------------------+-----------+--------------+-----------------+-----+--------------------+--------------+--------+----+\n",
            "|0700026657| NULL|    5.0|This game is a bi...|10 17, 2015|A1HP7NVNPFMA4N|      Ambrosia075| NULL|but when you do i...|    1445040000|    true|NULL|\n",
            "|0700026657| NULL|    4.0|I played it a whi...|07 27, 2015|A1JGAP0185YJI6|           travis| NULL|But in spite of t...|    1437955200|   false|NULL|\n",
            "|0700026657| NULL|    3.0|            ok game.|02 23, 2015|A1YJWEXHQBWK2B|Vincent G. Mezera| NULL|         Three Stars|    1424649600|    true|NULL|\n",
            "|0700026657| NULL|    2.0|found the game a ...|02 20, 2015|A2204E1TH211HT|       Grandma KR| NULL|           Two Stars|    1424390400|    true|NULL|\n",
            "|0700026657| NULL|    5.0|great game, I lov...|12 25, 2014|A2RF5B5H74JLPE|              jon| NULL|      love this game|    1419465600|    true|NULL|\n",
            "|0700026657| NULL|    4.0|i liked a lot som...|11 13, 2014|A11V6ZJ2FVQY1D|   IBRAHIM ALBADI| NULL|           Anno 2070|    1415836800|    true|NULL|\n",
            "|0700026657| NULL|    1.0|I'm an avid gamer...| 08 2, 2014|A1KXJ1ELZIU05C|       Creation27| NULL|Avoid This Game -...|    1406937600|   false|NULL|\n",
            "|0700026657| NULL|    5.0|I bought this gam...| 03 3, 2014|A1WK5I4874S3O2|       WhiteSkull| NULL|A very good game ...|    1393804800|    true|NULL|\n",
            "|0700026657| NULL|    5.0|I have played the...|02 21, 2014| AV969NA4CBP10|  Travis B. Moore| NULL|Anno 2070 more li...|    1392940800|    true|NULL|\n",
            "|0700026657| NULL|    4.0|I liked it and ha...|06 27, 2013|A1EO9BFUHTGWKZ|         johnnyz3| NULL|          Pretty fun|    1372291200|    true|NULL|\n",
            "|0700026657| NULL|    4.0|4 Stars because t...|12 28, 2012|A2M8JTIST6FPZZ|  Amazon Customer| NULL|My boys enjoys th...|    1356652800|    true|NULL|\n",
            "|0700026657| NULL|    1.0|I've bought and p...|05 15, 2012|A1LMJ9W8UX1H5B|           Rob NY| NULL|     SAY NO TO DRM!!|    1337040000|   false|  28|\n",
            "|0700099867| NULL|    5.0|Loved playing Dir...|08 14, 2011| AN3YYDZAS3O1Y|              Bob| NULL|A step up from Di...|    1313280000|    true|  11|\n",
            "|0700099867| NULL|    5.0|I'm not quite fin...|06 28, 2011|A38NXTZUFB1O2K|             FiSH| NULL| Best in the series!|    1309219200|   false|NULL|\n",
            "|0700099867| NULL|    5.0|lot of people don...|06 18, 2011|A15PIAQT55GNCA|        Suk W. Yu| NULL|this games is ama...|    1308355200|   false|NULL|\n",
            "|0700099867| NULL|    4.0|I had Dirt 2 on X...|06 14, 2011|A361M14PU2GUEG|       Angry Ryan| NULL|              DIRT 3|    1308009600|    true|   2|\n",
            "|0700099867| NULL|    5.0|This is a must ha...|06 13, 2011|A2LQCBLLJVVR5T|         Timmiley| NULL|BEST GRAPHICS OF ...|    1307923200|   false|  14|\n",
            "|0700026398| NULL|    1.0|I'm sure I would ...|05 18, 2013|A1NQ759X8WPIVV|             Lynn| NULL|      Requires steam|    1368835200|    true|NULL|\n",
            "|0700026398| NULL|    1.0|Update June 2013:...|01 10, 2013| APFCXOFX0KUPN|               --| NULL|               Skip!|    1357776000|   false|NULL|\n",
            "|0700026398| NULL|    4.0|I will open with ...|12 26, 2012|A2GPRA9HHLOC4B|      Wicasawakan| NULL|Great game with d...|    1356480000|   false|  12|\n",
            "+----------+-----+-------+--------------------+-----------+--------------+-----------------+-----+--------------------+--------------+--------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.select(\"overall\",\"reviewText\")\n",
        "#df.show(truncate=False)"
      ],
      "metadata": {
        "id": "FvIHmkzEsFzU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a delta frame from the df and save to the hdfs\n",
        "df.write.format(\"delta\").mode(\"overwrite\").save(\"/content/drive/MyDrive/GoogleColab\")"
      ],
      "metadata": {
        "id": "BE3hrPfssWqP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fetch the delta table from hdfs\n",
        "delta_df = spark.read.format(\"delta\").load(\"/content/drive/MyDrive/GoogleColab\")\n",
        "delta_df.show(3,truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHr8a5tlqtpp",
        "outputId": "aad70160-ac86-4126-fc00-fea359bec73c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|overall|reviewText                                                                                                                                                                                                                                                                                               |\n",
            "+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|5.0    |This game is a bit hard to get the hang of, but when you do it's great.                                                                                                                                                                                                                                  |\n",
            "|4.0    |I played it a while but it was alright. The steam was a bit of trouble. The more they move these game to steam the more of a hard time I have activating and playing a game. But in spite of that it was fun, I liked it. Now I am looking forward to anno 2205 I really want to play my way to the moon.|\n",
            "|3.0    |ok game.                                                                                                                                                                                                                                                                                                 |\n",
            "+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'overall' to binary (0 or 1)\n",
        "delta_df = delta_df.withColumn(\"overall\", when(delta_df[\"overall\"] < 3, 0).otherwise(1))\n",
        "#delta_df.show(3,truncate=False)"
      ],
      "metadata": {
        "id": "SFcJlHVytW5f"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom transformer to remove special characters\n",
        "class RemoveSpecialCharactersTransformer(Transformer):\n",
        "    def __init__(self, inputCol, outputCol):\n",
        "        super(RemoveSpecialCharactersTransformer, self).__init__()\n",
        "        self.inputCol = inputCol\n",
        "        self.outputCol = outputCol\n",
        "\n",
        "    def _transform(self, df: DataFrame) -> DataFrame:\n",
        "#        print(f\"Ran _transform with data {df[self.inputCol]}\")\n",
        "        return df.withColumn(self.outputCol, udf(remove_special_characters)(df[self.inputCol]))\n",
        "\n",
        "# Define the UDF to remove special characters\n",
        "def remove_special_characters(text):\n",
        "    print(text, '\\n')\n",
        "    if type(text)==str:\n",
        "        return re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
        "\n",
        "    return \"\"\n",
        "\n",
        "# Create instances of the custom transformers\n",
        "remove_special_chars = RemoveSpecialCharactersTransformer(inputCol=\"reviewText\", outputCol=\"cleanText\")\n"
      ],
      "metadata": {
        "id": "X9oNed9mtejk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the reviewText\n",
        "tokenizer = Tokenizer(inputCol=\"cleanText\", outputCol=\"token\")"
      ],
      "metadata": {
        "id": "WO5LP2k-t8Vf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the StopWordsRemover\n",
        "stop_words_remover = StopWordsRemover(inputCol=\"token\", outputCol=\"words\")\n",
        "\n",
        "# Vectorize the filtered words using HashingTF\n",
        "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"features\")"
      ],
      "metadata": {
        "id": "NQ7ymJFHtieb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "train_data, test_data = delta_df.randomSplit([0.7, 0.3])"
      ],
      "metadata": {
        "id": "EfLN0rPsuZuk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Naive Bayes model\n",
        "nb = NaiveBayes(featuresCol=\"features\", labelCol=\"overall\")\n",
        "\n",
        "# Create a pipeline with Tokenizer, StopWordsRemover, HashingTF, and Naive Bayes\n",
        "pipeline = Pipeline(stages=[remove_special_chars,tokenizer, stop_words_remover, hashingTF, nb])\n"
      ],
      "metadata": {
        "id": "ke3rdpzYo1Wb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model = pipeline.fit(train_data)"
      ],
      "metadata": {
        "id": "VOQmI9ckvZpT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test data\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Evaluate the model using MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"overall\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7v-f0_R4x7Xn",
        "outputId": "7b7094eb-c314-4a22-a4df-5506fa0a2ac4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9148268369235721\n"
          ]
        }
      ]
    }
  ]
}